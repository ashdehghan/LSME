{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Deep Dive\n",
    "\n",
    "This notebook explores the CNN and DNN encoders in detail.\n",
    "\n",
    "## Topics\n",
    "1. CNN vs DNN architecture comparison\n",
    "2. Training curves and convergence\n",
    "3. Reconstruction quality\n",
    "4. Hyperparameter tuning\n",
    "5. Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lsme import LSME, CNNEncoder, DNNEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Signature Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph and compute signature matrices\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "lsme = LSME(method='stochastic', max_hops=2, n_samples=200, \n",
    "            verbose=False, random_state=42)\n",
    "result = lsme.fit_transform(G)\n",
    "\n",
    "sig_matrices = result['signature_matrices']\n",
    "layer_info = result['layer_info']\n",
    "\n",
    "print(f\"Generated {len(sig_matrices)} signature matrices\")\n",
    "sizes = [m.shape[0] for m in sig_matrices.values()]\n",
    "print(f\"Matrix sizes: min={min(sizes)}, max={max(sizes)}, unique={len(set(sizes))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN vs DNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN encoder\n",
    "cnn_encoder = CNNEncoder(\n",
    "    embedding_dim=32,\n",
    "    hidden_channels=[32, 64, 128],\n",
    "    num_epochs=100,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cnn_embeddings = cnn_encoder.fit_transform(sig_matrices, layer_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DNN encoder\n",
    "dnn_encoder = DNNEncoder(\n",
    "    embedding_dim=32,\n",
    "    hidden_dims=[512, 256, 128],\n",
    "    num_epochs=100,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dnn_embeddings = dnn_encoder.fit_transform(sig_matrices, layer_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reconstruction Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reconstruction errors\n",
    "cnn_errors = cnn_encoder.reconstruction_error(sig_matrices, layer_info)\n",
    "dnn_errors = dnn_encoder.reconstruction_error(sig_matrices, layer_info)\n",
    "\n",
    "print(f\"CNN avg error: {np.mean(list(cnn_errors.values())):.6f}\")\n",
    "print(f\"DNN avg error: {np.mean(list(dnn_errors.values())):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original vs reconstructed\n",
    "cnn_recon = cnn_encoder.decode(cnn_embeddings)\n",
    "dnn_recon = dnn_encoder.decode(dnn_embeddings)\n",
    "\n",
    "node = 0  # Node to visualize\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "im0 = axes[0].imshow(sig_matrices[node], cmap='Blues', vmin=0, vmax=1)\n",
    "axes[0].set_title('Original')\n",
    "plt.colorbar(im0, ax=axes[0])\n",
    "\n",
    "# Crop reconstruction to original size\n",
    "orig_size = sig_matrices[node].shape[0]\n",
    "im1 = axes[1].imshow(cnn_recon[node][:orig_size, :orig_size], cmap='Blues', vmin=0, vmax=1)\n",
    "axes[1].set_title(f'CNN Reconstruction\\nMSE: {cnn_errors[node]:.6f}')\n",
    "plt.colorbar(im1, ax=axes[1])\n",
    "\n",
    "im2 = axes[2].imshow(dnn_recon[node][:orig_size, :orig_size], cmap='Blues', vmin=0, vmax=1)\n",
    "axes[2].set_title(f'DNN Reconstruction\\nMSE: {dnn_errors[node]:.6f}')\n",
    "plt.colorbar(im2, ax=axes[2])\n",
    "\n",
    "plt.suptitle(f'Node {node} Reconstruction Comparison')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding Dimension Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different embedding dimensions\n",
    "dims = [8, 16, 32, 64, 128]\n",
    "cnn_results = []\n",
    "dnn_results = []\n",
    "\n",
    "for dim in dims:\n",
    "    # CNN\n",
    "    enc = CNNEncoder(embedding_dim=dim, num_epochs=50, verbose=False, random_state=42)\n",
    "    enc.fit(sig_matrices, layer_info)\n",
    "    errors = enc.reconstruction_error(sig_matrices, layer_info)\n",
    "    cnn_results.append(np.mean(list(errors.values())))\n",
    "    \n",
    "    # DNN\n",
    "    enc = DNNEncoder(embedding_dim=dim, num_epochs=50, verbose=False, random_state=42)\n",
    "    enc.fit(sig_matrices, layer_info)\n",
    "    errors = enc.reconstruction_error(sig_matrices, layer_info)\n",
    "    dnn_results.append(np.mean(list(errors.values())))\n",
    "    \n",
    "    print(f\"dim={dim:3d}: CNN={cnn_results[-1]:.6f}, DNN={dnn_results[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dims, cnn_results, 'o-', label='CNN', linewidth=2)\n",
    "plt.plot(dims, dnn_results, 's-', label='DNN', linewidth=2)\n",
    "plt.xlabel('Embedding Dimension')\n",
    "plt.ylabel('Average Reconstruction MSE')\n",
    "plt.title('Reconstruction Error vs Embedding Dimension')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained encoder\n",
    "cnn_encoder.save('cnn_encoder.pt')\n",
    "print(\"Saved cnn_encoder.pt\")\n",
    "\n",
    "# Load and verify\n",
    "loaded_encoder = CNNEncoder.load('cnn_encoder.pt')\n",
    "loaded_embeddings = loaded_encoder.encode(sig_matrices, layer_info)\n",
    "\n",
    "# Verify embeddings match\n",
    "for node in sig_matrices:\n",
    "    assert np.allclose(cnn_embeddings[node], loaded_embeddings[node]), f\"Mismatch for node {node}\"\n",
    "\n",
    "print(\"Loaded encoder produces identical embeddings!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "import os\n",
    "os.remove('cnn_encoder.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **CNN**: Better for larger matrices, captures spatial patterns\n",
    "- **DNN**: Simpler, faster training, good for smaller matrices\n",
    "- Higher embedding dimensions reduce reconstruction error but may overfit\n",
    "- Models can be saved and loaded for reuse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
